{"title":"","date":"2024-06-21T03:48:14.375Z","date_formatted":{"ll":"Jun 21, 2024","L":"06/21/2024","MM-DD":"06-21"},"updated":"2024-06-20T19:48:14.375Z","content":"<p>今天分享一个论文<a href=\"https://www.aclweb.org/anthology/2020.acl-main.630.pdf,\" title=\"tBERT: Topic Models and BERT Joining Forces for Semantic Similarity Detection\" target=\"_blank\">ACL2020-tBERT</a>，论文主要融合主题模型和BERT去做语义相似度判定，在特定领域使用这个模型，效果更明显。</p>\n<p>掌握以下几点：</p>\n<ol>\n<li>【CLS】向量拼接两个句子各自的主题模型，效果有提升</li>\n<li>尤其是在特定领域的数据集合会有更好的表现。</li>\n</ol>\n<h1 id=\"1.-架构图\">1. 架构图<a title=\"#1.-架构图\" href=\"#1.-架构图\"></a></h1>\n<p>先看架构图：</p>\n<p><img src=\"https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-05-140314.jpg\" alt=\"tbert架构图\" loading=\"lazy\" class=\"φbp\"></p>\n<p>模型架构比较简单，BERT这边使用的【CLS】输出向量：$C=BERT(S_{1},S_{2})$</p>\n<p>主题模型使用两种，LDA和GSDMM，主要是因为LDA在长文本效果更好；GSDMM在短文本效果更好。</p>\n<p>获取主题模型如下所示：</p>\n<p>$$D_{1} = TopicModel([T_{1},…,T_{N}]) \\in R^{t}$$</p>\n<p>$$D_{2} = TopicModel([T^{,}<em>{1},…,T^{,}</em>{M}]) \\in R^{t}$$</p>\n<p>$t$ 代表的是主题数量，N是$S_{1}$的字数量，M是$S_{2}$的字数量</p>\n<p>进而我们可以得到单词的主题分布:</p>\n<p>$w_{i} = TopicModel(T_{i})$</p>\n<p>$$W_{1} = \\frac{\\sum^{N}<em>{i=1}w</em>{i}}{N} \\in R^{t}$$</p>\n<p>$$W_{2} = \\frac{\\sum^{M}<em>{i=1}w^{,}</em>{i}}{M} \\in R^{t}$$</p>\n<p>所以在最后和【CLS】连接的时候，可以使用文档主题$D_{1}和D_{2}$，也可以使用单词主题$W_{1}和W_{2}$。</p>\n<h1 id=\"2.实验效果\">2.实验效果<a title=\"#2.实验效果\" href=\"#2.实验效果\"></a></h1>\n<p><img src=\"https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-05-140316.jpg\" alt=\"tBERT实验效果\" loading=\"lazy\" class=\"φbp\"></p>\n<p>看实验效果，LDA效果会比GSDMM更好一点。</p>\n<p>其实有一个比较有意思的点是，BERT的建模能力已经足够强了，为啥加上主题模型还会有提升。</p>\n<p>换句话说，主题模型在基于BERT的方向上，能够在哪些方面提升。</p>\n<p>作者是这么做的实验，他选了和主题模型相关的三个属性：实体，特定领域词和不规范拼写。根据三个属性抽取样本，总共500个， 然后让BERT和tBERT做预测。</p>\n<p><img src=\"https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-05-140315.jpg\" alt=\"tBERT三个属性实验\" loading=\"lazy\" class=\"φbp\"></p>\n<p>看实验效果是这样的，发现在特定领域tBERT效果更明显一点。</p>\n<p>作者认为在预训练的时候，可能是BERT碰到特定领域词汇的机会比较少，没有很好的学习到这些信息，所以主题模型很好的补充了这部分信息。</p>\n<p>不过，感觉这个实验并不充分，一个属性这块挑选感觉有点不太充分，还有一个是样本数量感觉太少了，500个…</p>\n<h1 id=\"总结\">总结<a title=\"#总结\" href=\"#总结\"></a></h1>\n<p>说一下掌握的知识点：</p>\n<ol>\n<li>【CLS】向量拼接两个句子各自的主题模型，效果有提升</li>\n<li>尤其是在特定领域的数据集合会有更好的表现。</li>\n</ol>\n<p>说一下我自己的思考，关于特定领域这块。一般来说，微调是可以解决这个问题的。</p>\n<p>不过看作者的实验，即使是微调之后的BERT，在特定领域这块，效果也没有tBERT好，说明主题模型在这块还是很有用的。</p>\n<p>进一步思考，可不可以这么推论，如果说我们的任务输入越是特定领域，那么假如tBERT越有明显的提升呢？</p>\n<p>这个感兴趣的大家可以去试一试，比如医疗领域，比如金融领域之类的。</p>\n","link":"links/NLP_ability/深度学习自然语言处理/Bert/tBERT-BERT融合主题模型","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/tBERT-BERT融合主题模型/","toc":[{"id":"1.-架构图","title":"1. 架构图","index":"1"},{"id":"2.实验效果","title":"2.实验效果","index":"2"},{"id":"总结","title":"总结","index":"3"}],"reward":true}