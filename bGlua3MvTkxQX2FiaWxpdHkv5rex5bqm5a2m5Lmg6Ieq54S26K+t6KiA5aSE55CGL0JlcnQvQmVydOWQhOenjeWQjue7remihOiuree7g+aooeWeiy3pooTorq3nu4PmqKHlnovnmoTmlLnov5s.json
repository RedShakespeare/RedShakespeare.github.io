{"title":"","date":"2024-06-21T03:48:13.705Z","date_formatted":{"ll":"Jun 21, 2024","L":"06/21/2024","MM-DD":"06-21"},"updated":"2024-06-20T19:48:13.705Z","content":"<p>Bert各种后续预训练模型-预训练模型的改进</p>\n<p>参考资料：</p>\n<p>站在BERT肩膀上的NLP新秀们（PART II） - kaiyuan的文章 - 知乎<br>\n<a href=\"https://zhuanlan.zhihu.com/p/68362016\" target=\"_blank\">https://zhuanlan.zhihu.com/p/68362016</a></p>\n<p>√ XLMs from Facebook</p>\n<p>√ LASER from Facebook</p>\n<p>√ MASS from Microsoft</p>\n<p>√ UNILM from Microsoft</p>\n<ol>\n<li>邱锡鹏老师发表了关于NLP预训练模型的综述《Pre-trained Models for Natural Language Processing: A Survey》</li>\n</ol>\n<p>这里有一个对这个的解读，写的非常好，在这个文章中，这个作者也列出来了自己的另外另个文章，可以看一看<br>\nNLP算法面试必备！史上最全！PTMs：NLP预训练模型的全面总结 - JayLou娄杰的文章 - 知乎<br>\n<a href=\"https://zhuanlan.zhihu.com/p/115014536\" target=\"_blank\">https://zhuanlan.zhihu.com/p/115014536</a><br>\n当然在这里文章里面，有一个链接，非常重要，就是对预训练模型单模型的精度，注意这里是精度，都是链接到了知乎文章<br>\n写的都是非常好！！！！！非常好，链接地址在这里<a href=\"https://github.com/loujie0822/Pre-trained-Models\" target=\"_blank\">https://github.com/loujie0822/Pre-trained-Models</a><br>\n这里链接一定要看</p>\n<p>这里还有一个关于邱老师综述的解读，也很好<br>\n论文笔记 - NLP 预训练模型综述 - 徐阿衡的文章 - 知乎<br>\n<a href=\"https://zhuanlan.zhihu.com/p/139015428\" target=\"_blank\">https://zhuanlan.zhihu.com/p/139015428</a></p>\n","link":"links/NLP_ability/深度学习自然语言处理/Bert/Bert各种后续预训练模型-预训练模型的改进","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/Bert/Bert各种后续预训练模型-预训练模型的改进/","reward":true}