{"title":"","date":"2024-06-21T03:20:43.233Z","date_formatted":{"ll":"Jun 21, 2024","L":"06/21/2024","MM-DD":"06-21"},"updated":"2024-06-20T19:20:43.233Z","content":"<p>大概会花一到两周的时间，把 transformer 系统的讲一遍，可能会涉及到到 Bert/GPT 的一些基本知识，每天只讲一个知识点。</p>\n<p>所有的关于NLP知识的文章都会放在下面这个仓库，大家快去看。</p>\n<p><a href=\"https://github.com/DA-southampton/NLP_ability\" target=\"_blank\">https://github.com/DA-southampton/NLP_ability</a></p>\n<p>预告一下明天内容，是关于transformer位置编码的讲解，很多同学对位置编码这个概念很模糊，只是知道是正余弦函数，别的就不太清楚，我们之后花几篇文章好好聊一聊这个概念。这个已经更新在github，想看的朋友可以提前去看一哈。</p>\n<h3 id=\"正文\">正文<a title=\"#正文\" href=\"#正文\"></a></h3>\n<p>Transformer 分为两个部分，encoder 侧 和 decoder 侧。今天，我们聊一下 encoder 侧。这部分由 N 个完全相同的大模块堆叠而成（原论文N=6）。</p>\n<p>这个结构怎么理解？这个构造就需要我们确保每一个模块的输入和输出维度是相同的，在实现代码的时候，我们只需要完成一个模块的代码的构造就可以。</p>\n<p>注解：你可以把这个过程想象成 RNN 竖过来的一个流程，是不是就很好理解（当然这样想只是帮助你理解）。</p>\n<p>其次对于这每一个大的模块，又分为两个模块，分别是多头注意力层和前馈神经网络层。进一步拆分，多头注意力层可以分为注意力层和 Add&amp;Norm 层。前馈神经网络可以分为 Linear 层和 Add&amp;Norm 层。</p>\n<p>多头注意力层，核心点在于 Q/K/V 三个矩阵，其中 Q/K 矩阵生成权重矩阵(经由softmax)，随后和V矩阵得到加权和。</p>\n<p>这个过程重复了 n_heads 次，这个 n_heads 代表的就是头的数目，这里需要注意的是我们需要确保 hidden_size/n_heads 需要为一个整数，不然代码会报错。</p>\n<p>Add 代表一个残差结构。对于残差结构，可以使得信息前后向传播更加顺畅，缓解了梯度破碎问题。在 NLP 角度来看，残差结构一定程度上促进了 NLP 网络结构向窄而深的方向发展。</p>\n<p>我们可以把 Transformer 和之前的模型对比一下，比如 RNN 模型，一般来说，我们会选择 单层RNN 或者 一个 Bilstm，对于这些比较传统的模型，只是在时间长度上进行了延展，并没有在深度上做的太深。</p>\n<p>所以说，残差结构是有助于网路变深的。</p>\n<p>顺便联想一下 Elmo，使用的是 双层双向lstm，训练起来已经非常慢了，所以对于RNN这种比较传统的模型，做深太难了，GNMT也是用了很多的 tricks 进行加速训练。</p>\n<p>Norm 代表的是 Layer Normalization。为什么这里使用 Layer Normalization，而不是BN，这个后面有文章说，这里直白的回答就是，BN的效果差，所以不用。</p>\n<p>随后多头注意力层的输出经过前馈神经网络。对前馈神经网络，比较简单，我们需要注意的是它分为两个 Linear 层，第一层的激活函数为 Relu，第二层没有使用激活函数。</p>\n<p>最后我们谈一下整个encoder的输入和输出。</p>\n<p>先说输入，分为两个部分：word embedding 和 position encoding</p>\n<p>word embedding 没什么可说的，初始化后跟着训练或者使用word2vec这种已经有的看具体任务的效果。</p>\n<p>position encoding 这里 transformer 使用的是 正余弦函数进行表达。其实这里进行初始化然后进行训练也是可以的，论文原作者的实验表明效果基本没区别。</p>\n<p>对于 position encoding 表示的绝对位置，这点大家都没异议，那么 position encoding 究竟有没有表达相对位置信息，之后会有个文章专门讲讲这个知识点。</p>\n<p>然后说一下 encoder的输出，感觉很少有人谈到这里。</p>\n<p>encoder 的输出需要注意的细节点在于它需要和 decoder做交互，所以它的输出为 K/V 矩阵，记住这个细节点，<strong>Q 矩阵来自decoder模块，K/V矩阵来自encoder</strong>。</p>\n<p>写到这里，我估摸这三分钟差不多能看完，现在没有留言功能，有问题大家在公众号对话框发送，我后台能看见。</p>\n<p>能点个在看，老铁们 ！！鞠躬感谢！！</p>\n","link":"links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/3分钟从零解读Transformer的Encoder","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/Transformer/3分钟从零解读Transformer的Encoder/","toc":[{"id":"正文","title":"正文","index":"1"}],"reward":true}