{"title":"","date":"2024-06-21T01:54:07.329Z","date_formatted":{"ll":"Jun 21, 2024","L":"06/21/2024","MM-DD":"06-21"},"updated":"2022-08-13T11:56:31.000Z","content":"<p>命名体识别</p>\n<p>关于这一块，主要是参考了美团ner的文章，写的非常的好：</p>\n<p>美团搜索中NER技术的探索与实践<br>\n<a href=\"https://tech.meituan.com/2020/07/23/ner-in-meituan-nlp.html\" target=\"_blank\">https://tech.meituan.com/2020/07/23/ner-in-meituan-nlp.html</a></p>\n<p>中文NER的正确打开方式: 词汇增强方法总结 (从Lattice LSTM到FLAT) - JayLou娄杰的文章 - 知乎<br>\n<a href=\"https://zhuanlan.zhihu.com/p/142615620\" target=\"_blank\">https://zhuanlan.zhihu.com/p/142615620</a></p>\n<p>实际工作中做实体识别，分为两个方向：词典匹配和模型预测。一般情况下，两者会被同时使用，相辅相成。</p>\n<h2 id=\"方法：词典匹配+模型预测\">方法：词典匹配+模型预测<a title=\"#方法：词典匹配+模型预测\" href=\"#方法：词典匹配+模型预测\"></a></h2>\n<p>首先聊一下为什么使用词典匹配。对于词典匹配来说，很简单就是，来一个句子，看句子中有没有含有我的字典中的词汇，如果有，直接输出就可以，这个过程匹配速度很快，不存在性能上的瓶颈。</p>\n<p>这个时候，我们要思考一个问题，词典匹配上线不存在性能上的瓶颈，那么它的瓶颈在哪里？</p>\n<p>首先，语义消歧问题：我的词典是分类别的，就是说针对不同的垂直领域我会有不同的词典列表，即美食含有一个词典列表，景点含有一个列表，以此类推，类别越多，你的垂直度就会越好。美团文章有这么一个例子，query是”黄鹤楼美食“，那么在词典匹配的时候会出现这样一种情况，就是景点词典匹配上了”黄鹤楼“，美食词典也匹配上了”黄鹤楼“（可能是北京一个美食商家名称）。</p>\n<p>那么，我们选择哪一个作为输出？这个例子就显示了一个问题，词典匹配不能解决语义消歧功能。而模型预测能够有泛化能力。</p>\n<p>其次，词典数量有限，泛化能力比较差：词典效果再好，但是它的数量是有限的，这就会出现OOV情况。缓解这个问题，有两种办法，一个是来做实体挖掘的方式不同的补充实体库，第二个就是使用深度学习的方式进行模型预测实体。</p>\n<p>这个时候，会思考一个问题，就是词典匹配和模型预测两路的结果，如何合并输出？</p>\n<p>美团是训练了要给CRF打分器，这一步我猜测是这么做的：</p>\n<p>对于我来说，两者完全可以这么做：词典匹配全部输出，模型预测提高阈值，至于这个阈值输出的阈值就看你自己去调了。</p>\n<h2 id=\"词典匹配\">词典匹配<a title=\"#词典匹配\" href=\"#词典匹配\"></a></h2>\n<h3 id=\"离线挖掘补充实体库\">离线挖掘补充实体库<a title=\"#离线挖掘补充实体库\" href=\"#离线挖掘补充实体库\"></a></h3>\n<p>词典匹配的一个瓶颈问题就是数量有限，OOV问题会比较明显。也就是说，有些词语不是那么正常，比如”爷青结“，但是这些词有需要补充到实体库。这个时候就需要我们离线的从数据中对实体进行挖掘。</p>\n<p>离线挖掘首先面临的一个问题是数据问题。数据如果是结构化数据，就很好办了。比如说直接从电影榜单获取到电影实体，从电视剧榜单获取电视剧的实体等等吧，这个没有什么难度。</p>\n<p>如果数据是非结构的数据怎么办？什么叫做非结构化数据呢？比说微博的博文文本，这个是UGC内容，就是我们平常说的话。</p>\n<p>从非结构化数据中提取出实体才是我们想要的东西。这个过程应该是分为两个步骤的，首先第一步，提取实体，第二步我们需要对实体分类。也就是我们的实体是需要对应到不同的类别词典中。</p>\n<p>美团在这一点说自己使用的是新词发现的一个流程来做实体识别。其实我仔细思考了他的这个流程，它和常规的新词发现还不太一样。</p>\n<p>首先，我们知道新词发现一般来说分为有监督和无监督。有监督就是序列标注，进行中文分词，结果中不再词库的就是我们的新词。无监督就是凝固度和自由度来评判词汇是不是新词。</p>\n<p>这个是新词发现的流程，但是我们要做的是找到新的实体，如果仅仅是做新词发现，肯定不能保证你挖掘出来的新词就是一个实体类别，也有可能是一些不是实体的那种网络新词。</p>\n<p>所以美团这边只是借鉴了新词发现的一部分。</p>\n<p>它的具体流程是这样的：</p>\n<ol>\n<li>\n<p>挖掘频繁集合作为候选</p>\n</li>\n<li>\n<p>候选集中的词语和已有积累的实体交集作为正样本。比如”烧烤“在频繁集合中有，在已有的实体词典中也有，就是一个正样本。基于负采样生成负样本。</p>\n</li>\n<li>\n<p>提取正负样本四个维度特征训练二分类判断是不是一个实体。</p>\n</li>\n</ol>\n<p>注意看到这第三点，从这个点，我发现一个问题。学习的目标是什么？二元分类判断词汇是不是实体。如果是实体，这个实体的数据来源于哪里？是交集，所以从本质上是已积累的实体。所以，我们相当于在挖掘UGC内容中，和我已经积累的实体<br>\n有相同特性的实体，至于这个实体是不是一个新词，不是我们考虑的。</p>\n<p>负样本中也有部分是高质量实体，也就是说我挖掘出来的高频繁集合有些也是比较好的实体，但是由于没存在交集中，所以被认为是负样本了，所以这个时候可以使用集成多个弱分类器的方式减少误差。</p>\n<p>接下来，我们使用的是Bert做了一个短语质量评分。对于这一个部分，其实很有意思，经过上面这个步骤，我们获取到了大量的正负实体。我们可以这样想一下，美团搜索其实有这样一个特点，就是说，我们基本上的搜索和大搜很不一样，我们的搜索都很垂直，<br>\n而且很短，都是很有意义的，比如我直接就是找某个商家名称，某个地方，这就是一个实体。</p>\n<p>所以，我们完全可以把搜索次数大于一定阈值的词条作为一个实体，而且这个实体天然就具有高质量，因为是人搜出来的。美团做了这样一件事情，把这个搜索记录和正正实体的交集作为正样本，把负实体中减去搜索记录作为负样本，做一个短语质量评分。</p>\n<p>这里的短语质量评分在我看来更像是一种判断实体是不是符合语言模型的标准。</p>\n<p>在预测的时候，我是这么想的，我们首先筛选出来正实体，然后短语质量打分挑选出高质量实体。</p>\n<p>在得到实体之后，我们要做的一个事情就是对实体进行分类，放到不同类别的词典中去。 这一块美团使用的autoner，这个我待定更新</p>\n","link":"links/NLP_ability/深度学习自然语言处理/命名体识别/词典匹配+模型预测-实体识别两大法宝","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/命名体识别/词典匹配+模型预测-实体识别两大法宝/","toc":[{"id":"方法：词典匹配+模型预测","title":"方法：词典匹配+模型预测","index":"1"},{"id":"词典匹配","title":"词典匹配","index":"2","children":[{"id":"离线挖掘补充实体库","title":"离线挖掘补充实体库","index":"2.1"}]}],"reward":true}