{"title":"","date":"2024-06-21T01:54:07.339Z","date_formatted":{"ll":"Jun 21, 2024","L":"06/21/2024","MM-DD":"06-21"},"updated":"2022-08-13T11:56:31.000Z","content":"<p>今天分享一个论文<a href=\"%E4%BD%BF%E7%94%A8%E8%B4%9F%E7%9B%91%E7%9D%A3%E7%9A%84%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB\" title=\"https://www.aclweb.org/anthology/2020.acl-main.33.pdf\">Text Classification with Negative Supervision</a>；</p>\n<p>论文思路比较简单，可以用一句话来说明就是：使用负监督+多任务的方式，可以扩大文本表达在输入语句语义相似的情况下的差异性。</p>\n<p>接下来详细说一下。</p>\n<h1 id=\"1.-语义相似标签不同的问题\">1. 语义相似标签不同的问题<a title=\"#1.-语义相似标签不同的问题\" href=\"#1.-语义相似标签不同的问题\"></a></h1>\n<p>文本分类中存在这样一种情况，有两个句子：</p>\n<p><img src=\"https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-11-30-093156.jpg\" alt=\"语义相似标签不同\" loading=\"lazy\" class=\"φbp\"></p>\n<p>句子A：感冒是个常见的疾病。这句话在标签数据中属于无标签数据。</p>\n<p>句子B: 我得了感冒。这句话在标签数据中数据标签为【感冒】的类别。</p>\n<p>但是我们的文本分类器，把两句话都分为了【感冒】这个类别。</p>\n<p>对于这种现象，可能是由于数据不充足，可能是由于其他原因，结果就是导致两个句子的【CLS】输出向量很接近，之后接一个分类器，分出的类别就是同一个。</p>\n<p>作者想解决的一个问题就是，想要通过一种方式，让模型知道，这两句话语义是不相似的。</p>\n<p>这个方式归到【ClS】这里，就是想要两个句子的【CLS】的输出是区分度大的。</p>\n<p>现在问题落在了了如何度量【CLS】的区分度？</p>\n<p>我读论文的时候第一想法是用KL散度或者交叉熵，然后发现作者使用的是两个【CLS】向量的余弦相似度进行度量。</p>\n<h1 id=\"模型架构\">模型架构<a title=\"#模型架构\" href=\"#模型架构\"></a></h1>\n<p>先总览一下模型架构：</p>\n<p><img src=\"https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-11-30-093154.jpg\" alt=\"负监督模型架构\" loading=\"lazy\" class=\"φbp\"></p>\n<p>这个架构其实很容易理解，初看命名Discriminator以为作者用的是对抗网络。。。</p>\n<p>作者使用的是一个很简单的多任务架构，分为了两个任务：</p>\n<ol>\n<li>Main Task：主要任务，做常规的文本分类任务</li>\n<li>Auxiliary Task：辅助任务，输入负样本（不同类别的样本），计算余弦下相似度。</li>\n</ol>\n<p>总体的损失函数如下：</p>\n<p><img src=\"https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-11-30-093155.jpg\" alt=\"负监督总体损失函数\" loading=\"lazy\" class=\"φbp\"></p>\n<p>辅助任务损失函数：</p>\n<p><img src=\"https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-11-30-093152.jpg\" alt=\"辅助任务损失函数\" loading=\"lazy\" class=\"φbp\"></p>\n<p>其实比较细节的一个点是辅助任务的输入样本是什么样子的。</p>\n<p>我们的本质是为了度量语义相似性的句子之间的文本表达向量尽可能的大。</p>\n<p>一个很朴素的想法就是，辅助任务中输入的是同类标签的数据，然后同类标签的输出向量和主要任务的输出向量做相似度度量，计算损失。</p>\n<p>但是，想一下这个过程，有没有解决作者最想解决的问题。</p>\n<p>我们会看一下最初的例子，两个句子是虽然有着相近的意思，但是有着不同的标签。所以我们这个关于辅助任务的输入样本的选择是有问题的。</p>\n<p>作者这边选择的是，与主要任务输入样本不同的标签数据作为辅助任务的输入，然后进行相似度的度量。</p>\n<p>当然作者又细分了两种模式：</p>\n<ol>\n<li>AAN：辅助任务输入的全部是与主要任务不同的标签数据</li>\n<li>AM：辅助任务包含一个与主要任务相同标签的数据，剩下的是不同标签数据。</li>\n</ol>\n<h1 id=\"结果分析\">结果分析<a title=\"#结果分析\" href=\"#结果分析\"></a></h1>\n<p>直接来看结果分析：</p>\n<p><img src=\"https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-11-30-093153.jpg\" alt=\"负监督结果分析\" loading=\"lazy\" class=\"φbp\"></p>\n<p>我其实比较感兴趣的是ACE这个为啥不行？按道理交叉熵应该也可以吧。</p>\n<p>作者的解释是，ACE效果不可以，恰恰说明了简单的多任务是不可行的，基于负监督的多任务是很必要的。</p>\n<h1 id=\"总结\">总结<a title=\"#总结\" href=\"#总结\"></a></h1>\n<p>总结一下从这个论文学到的东西，主要是就是一点，对使用不同标签数据的【CLS】输出向量进行余弦相似度的损失计算（作为多任务的辅助任务），可以提升表达向量的差异化。</p>\n<p>这个思路用在普通的编码器，应该也是适用的，感兴趣的可以试试。</p>\n","link":"links/NLP_ability/深度学习自然语言处理/文本分类/ACL2020-多任务负监督方式增加CLS表达差异性","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本分类/ACL2020-多任务负监督方式增加CLS表达差异性/","toc":[{"id":"1.-语义相似标签不同的问题","title":"1. 语义相似标签不同的问题","index":"1"},{"id":"模型架构","title":"模型架构","index":"2"},{"id":"结果分析","title":"结果分析","index":"3"},{"id":"总结","title":"总结","index":"4"}],"reward":true}