{"title":"","date":"2024-06-21T03:48:20.755Z","date_formatted":{"ll":"Jun 21, 2024","L":"06/21/2024","MM-DD":"06-21"},"updated":"2024-06-20T19:48:20.755Z","content":"<p>ESIM</p>\n<ol>\n<li>导入数据</li>\n</ol>\n<p>1.1 train_data = LCQMC_Dataset(train_file, vocab_file, max_length)</p>\n<p>通过LCQMC_Dataset 导入数据，在LCQMC_Dataset 中，做了这几件事情：</p>\n<p>1.1.1 p, h, self.label = load_sentences(LCQMC_file)</p>\n<p>读取数据文件，切分数据</p>\n<p>1.1.2 word2idx, _, _ = load_vocab(vocab_file)</p>\n<p>读取字典文件，从而获得 word2idx, idx2word, vocab</p>\n<p>1.1.3 self.p_list, self.p_lengths, self.h_list, self.h_lengths = word_index(p, h, word2idx, max_char_len)</p>\n<p>将数据转化为对应的数值，并且根据max_char_len进行切分或者截断</p>\n<p>1.1.4<br>\nself.p_list = torch.from_numpy(self.p_list).type(torch.long)<br>\nself.h_list = torch.from_numpy(self.h_list).type(torch.long)</p>\n<p>转化为对应的torch tensor</p>\n<p>1.2  数据batch化<br>\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)<br>\n按照batch进行读取。是torch的代码，我就不看了</p>\n<p>1.3 读取embedding文件<br>\nembeddings = load_embeddings(embeddings_file)<br>\n注意pad全为零</p>\n<ol start=\"2\">\n<li>\n<p>model构建<br>\nmodel = ESIM(hidden_size, embeddings=embeddings, dropout=dropout, num_classes=num_classes, device=device).to(device)</p>\n</li>\n<li>\n<p>为了方便，我把ESIM整体流程重点是attention的部分抽离了出来</p>\n</li>\n</ol>\n","link":"links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/src/ESIM-attention/ESIM代码解读","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/文本匹配和文本相似度/src/ESIM-attention/ESIM代码解读/","reward":true}