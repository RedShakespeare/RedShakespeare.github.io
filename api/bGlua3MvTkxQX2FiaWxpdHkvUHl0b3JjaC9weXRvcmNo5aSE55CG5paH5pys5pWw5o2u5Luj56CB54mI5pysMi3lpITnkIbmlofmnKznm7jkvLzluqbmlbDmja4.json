{"title":"","date":"2024-06-21T01:54:07.129Z","date_formatted":{"ll":"Jun 21, 2024","L":"06/21/2024","MM-DD":"06-21"},"updated":"2022-08-13T11:56:31.000Z","content":"<p>pytorch处理文本数据代码版本2-处理文本相似度数据</p>\n<p>这里代码参考的是：<a href=\"https://github.com/DA-southampton/TextMatch/blob/master/SiaGRU/data.py\" target=\"_blank\">https://github.com/DA-southampton/TextMatch/blob/master/SiaGRU/data.py</a><br>\n感谢原作者</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">Created on Thu Mar 12 15:30:14 2020</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">@author: zhaog</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">import</span> gensim</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> hanziconv <span class=\"keyword\">import</span> HanziConv  <span class=\"comment\">##dasou:中文文本处理库</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.data <span class=\"keyword\">import</span> Dataset</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">LCQMC_Dataset</span>(<span class=\"title class_ inherited__\">Dataset</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, LCQMC_file, vocab_file, max_char_len</span>):</span><br><span class=\"line\">        p, h, self.label = load_sentences(LCQMC_file)</span><br><span class=\"line\">        word2idx, _, _ = load_vocab(vocab_file)</span><br><span class=\"line\">        self.p_list, self.p_lengths, self.h_list, self.h_lengths = word_index(p, h, word2idx, max_char_len)</span><br><span class=\"line\">        self.p_list = torch.from_numpy(self.p_list).<span class=\"built_in\">type</span>(torch.long)</span><br><span class=\"line\">        self.h_list = torch.from_numpy(self.h_list).<span class=\"built_in\">type</span>(torch.long)</span><br><span class=\"line\">        self.max_length = max_char_len</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__len__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(self.label)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, idx</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.p_list[idx], self.p_lengths[idx], self.h_list[idx], self.h_lengths[idx], self.label[idx]</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># 加载word_index训练数据</span></span><br><span class=\"line\"><span class=\"comment\">##dasou: 使用了pandas这个库，将文本相似度数据相同的列提取出来进行处理，而不是针对每一行一个样本进行处理，其实看到这里这个代码存在的一个问题就是如果将来</span></span><br><span class=\"line\"><span class=\"comment\">##出来大的数据，也就是大的文件，pandas是没有办法直接全部读进来的，这是个缺点，不过对几个G的数据应该不存在这种问题</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_sentences</span>(<span class=\"params\">file, data_size=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    df = pd.read_csv(file,sep=<span class=\"string\">&#x27;\\t&#x27;</span>,header=<span class=\"literal\">None</span>)<span class=\"comment\">##dasou 为了适应我的数据格式</span></span><br><span class=\"line\">    p = <span class=\"built_in\">map</span>(get_word_list, df[<span class=\"number\">0</span>].values[<span class=\"number\">0</span>:data_size]) <span class=\"comment\">## p的每个元素类似这种 [&#x27;晚&#x27;, &#x27;上&#x27;, &#x27;尿&#x27;, &#x27;多&#x27;, &#x27;吃&#x27;, &#x27;什&#x27;, &#x27;么&#x27;, &#x27;药&#x27;]</span></span><br><span class=\"line\">    h = <span class=\"built_in\">map</span>(get_word_list, df[<span class=\"number\">1</span>].values[<span class=\"number\">0</span>:data_size])</span><br><span class=\"line\">    label = df[<span class=\"number\">2</span>].values[<span class=\"number\">0</span>:data_size]</span><br><span class=\"line\">    <span class=\"comment\">#p_c_index, h_c_index = word_index(p, h)</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> p, h, label</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># word-&gt;index</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">word_index</span>(<span class=\"params\">p_sentences, h_sentences, word2idx, max_char_len</span>):</span><br><span class=\"line\">    p_list, p_length, h_list, h_length = [], [], [], []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> p_sentence, h_sentence <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(p_sentences, h_sentences):</span><br><span class=\"line\">        p = [word2idx[word] <span class=\"keyword\">for</span> word <span class=\"keyword\">in</span> p_sentence <span class=\"keyword\">if</span> word <span class=\"keyword\">in</span> word2idx.keys()]</span><br><span class=\"line\">        h = [word2idx[word] <span class=\"keyword\">for</span> word <span class=\"keyword\">in</span> h_sentence <span class=\"keyword\">if</span> word <span class=\"keyword\">in</span> word2idx.keys()]</span><br><span class=\"line\">        p_list.append(p)</span><br><span class=\"line\">        p_length.append(<span class=\"built_in\">min</span>(<span class=\"built_in\">len</span>(p), max_char_len))</span><br><span class=\"line\">        h_list.append(h)</span><br><span class=\"line\">        h_length.append(<span class=\"built_in\">min</span>(<span class=\"built_in\">len</span>(h), max_char_len))</span><br><span class=\"line\">    p_list = pad_sequences(p_list, maxlen = max_char_len)</span><br><span class=\"line\">    h_list = pad_sequences(h_list, maxlen = max_char_len)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p_list, p_length, h_list, h_length</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 加载字典</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_vocab</span>(<span class=\"params\">vocab_file</span>):</span><br><span class=\"line\">    vocab = [line.strip() <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> <span class=\"built_in\">open</span>(vocab_file, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>).readlines()]</span><br><span class=\"line\">    word2idx = &#123;word: index <span class=\"keyword\">for</span> index, word <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(vocab)&#125;</span><br><span class=\"line\">    idx2word = &#123;index: word <span class=\"keyword\">for</span> index, word <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(vocab)&#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> word2idx, idx2word, vocab</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">&#x27;&#x27;&#x27; 把句子按字分开，中文按字分，英文数字按空格, 大写转小写，繁体转简体&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_word_list</span>(<span class=\"params\">query</span>):</span><br><span class=\"line\">    query = HanziConv.toSimplified(query.strip())</span><br><span class=\"line\">    regEx = re.<span class=\"built_in\">compile</span>(<span class=\"string\">&#x27;[\\\\W]+&#x27;</span>)<span class=\"comment\">#我们可以使用正则表达式来切分句子，切分的规则是除单词，数字外的任意字符串</span></span><br><span class=\"line\">    res = re.<span class=\"built_in\">compile</span>(<span class=\"string\">r&#x27;([\\u4e00-\\u9fa5])&#x27;</span>)<span class=\"comment\">#[\\u4e00-\\u9fa5]中文范围</span></span><br><span class=\"line\">    sentences = regEx.split(query.lower())</span><br><span class=\"line\">    str_list = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> sentence <span class=\"keyword\">in</span> sentences:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> res.split(sentence) == <span class=\"literal\">None</span>:</span><br><span class=\"line\">            str_list.append(sentence)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            ret = res.split(sentence)</span><br><span class=\"line\">            str_list.extend(ret)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> [w <span class=\"keyword\">for</span> w <span class=\"keyword\">in</span> str_list <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(w.strip()) &gt; <span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_embeddings</span>(<span class=\"params\">embdding_path</span>):</span><br><span class=\"line\">    model = gensim.models.KeyedVectors.load_word2vec_format(embdding_path, binary=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    embedding_matrix = np.zeros((<span class=\"built_in\">len</span>(model.index2word) + <span class=\"number\">1</span>, model.vector_size))</span><br><span class=\"line\">    <span class=\"comment\">#填充向量矩阵</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx, word <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(model.index2word):</span><br><span class=\"line\">        embedding_matrix[idx + <span class=\"number\">1</span>] = model[word]<span class=\"comment\">#词向量矩阵</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> embedding_matrix</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">pad_sequences</span>(<span class=\"params\">sequences, maxlen=<span class=\"literal\">None</span>, dtype=<span class=\"string\">&#x27;int32&#x27;</span>, padding=<span class=\"string\">&#x27;post&#x27;</span>,</span></span><br><span class=\"line\"><span class=\"params\">                  truncating=<span class=\"string\">&#x27;post&#x27;</span>, value=<span class=\"number\">0.</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot; pad_sequences</span></span><br><span class=\"line\"><span class=\"string\">    把序列长度转变为一样长的，如果设置了maxlen则长度统一为maxlen，如果没有设置则默认取</span></span><br><span class=\"line\"><span class=\"string\">    最大的长度。填充和截取包括两种方法，post与pre，post指从尾部开始处理，pre指从头部</span></span><br><span class=\"line\"><span class=\"string\">    开始处理，默认都是从尾部开始。</span></span><br><span class=\"line\"><span class=\"string\">    Arguments:</span></span><br><span class=\"line\"><span class=\"string\">        sequences: 序列</span></span><br><span class=\"line\"><span class=\"string\">        maxlen: int 最大长度</span></span><br><span class=\"line\"><span class=\"string\">        dtype: 转变后的数据类型</span></span><br><span class=\"line\"><span class=\"string\">        padding: 填充方法&#x27;pre&#x27; or &#x27;post&#x27;</span></span><br><span class=\"line\"><span class=\"string\">        truncating: 截取方法&#x27;pre&#x27; or &#x27;post&#x27;</span></span><br><span class=\"line\"><span class=\"string\">        value: float 填充的值</span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">        x: numpy array 填充后的序列维度为 (number_of_sequences, maxlen)</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    lengths = [<span class=\"built_in\">len</span>(s) <span class=\"keyword\">for</span> s <span class=\"keyword\">in</span> sequences]</span><br><span class=\"line\">    nb_samples = <span class=\"built_in\">len</span>(sequences)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> maxlen <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        maxlen = np.<span class=\"built_in\">max</span>(lengths)</span><br><span class=\"line\">    x = (np.ones((nb_samples, maxlen)) * value).astype(dtype)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx, s <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(sequences):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(s) == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"keyword\">continue</span>  <span class=\"comment\"># empty list was found</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> truncating == <span class=\"string\">&#x27;pre&#x27;</span>:</span><br><span class=\"line\">            trunc = s[-maxlen:]</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> truncating == <span class=\"string\">&#x27;post&#x27;</span>:</span><br><span class=\"line\">            trunc = s[:maxlen]</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">&quot;Truncating type &#x27;%s&#x27; not understood&quot;</span> % padding)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> padding == <span class=\"string\">&#x27;post&#x27;</span>:</span><br><span class=\"line\">            x[idx, :<span class=\"built_in\">len</span>(trunc)] = trunc</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> padding == <span class=\"string\">&#x27;pre&#x27;</span>:</span><br><span class=\"line\">            x[idx, -<span class=\"built_in\">len</span>(trunc):] = trunc</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">&quot;Padding type &#x27;%s&#x27; not understood&quot;</span> % padding)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>","link":"links/NLP_ability/Pytorch/pytorch处理文本数据代码版本2-处理文本相似度数据","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/Pytorch/pytorch处理文本数据代码版本2-处理文本相似度数据/","reward":true}