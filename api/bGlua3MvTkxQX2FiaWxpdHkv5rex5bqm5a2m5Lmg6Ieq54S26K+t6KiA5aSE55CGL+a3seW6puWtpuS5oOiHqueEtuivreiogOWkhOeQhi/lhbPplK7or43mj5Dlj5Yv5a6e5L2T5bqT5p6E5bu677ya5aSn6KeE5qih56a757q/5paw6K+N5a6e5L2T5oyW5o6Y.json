{"title":"","date":"2024-06-21T03:20:44.173Z","date_formatted":{"ll":"Jun 21, 2024","L":"06/21/2024","MM-DD":"06-21"},"updated":"2024-06-20T19:20:44.173Z","content":"<p>实体库构建：离线新词发现流程</p>\n<p>命名体识别我们一般有两个操作：词典匹配+模型预测。</p>\n<p>对于词典匹配来说，速度快，准确度高。但是有一个问题是由于不同人对同一个东西有不同的表达，所以OOV问题比较严重。</p>\n<p>缓解OOV，我们可以使用模型预测增加泛化，还可以离线挖掘实体进行补充实体库。</p>\n<p>美团在这个文章中提到了一种新词离线挖掘补充实体库的方法，我借鉴了其中的思路，并且用到了自己工作中，效果还不错。在这个文章，我主要是详细解读一下整个过程。</p>\n<p>我们聊一下为什么需要做新词发现？</p>\n<p>新词是什么？按照最普通的定义就是我词典中不存在的词汇都属于新词。如果按照这个思路去挖掘新词，我们一般使用两种方法：有监督和无监督。</p>\n<p>无监督一般来说就是使用紧密度加自由度调整阈值就可以提取新词。但是这种方法有一个问题，就是你这个阈值的调整到哪里才可以，这个取决于你的召回和精确的一个平衡。</p>\n<p>有监督的话，一个简单的思路就是序列标注做中文分词，出来的词汇不在字典中的我们就可以作为新词。</p>\n<p>但是我们想一下这样新词出现的是什么情况？</p>\n<p>举个最简单的例子，可能你挖掘出来的就是“爷青结”这样的词汇，确实是新词，不在我们已经有词典中，但是对于我们的实体库有没有帮助呢？</p>\n<p>有没有帮助要看我们的目的。如果说我们的目的是为了分词的准确，那么这个新词完全可以用，直接放到txt文件中，保证下回分类的准确。</p>\n<p>但是在这里，我们是做的事情是为了补充实体库，也就是需要有意义的词汇，比如说“外滩十八号”这种词汇。</p>\n<p>所以，普通的新词发现的有监督和无监督方法只能挖掘词汇，不能保证挖掘的是实体。</p>\n<p>基于此目的，可以借鉴新词挖掘的思路，对词汇做二元分类判断是不是实体的有监督方法就很容易想到。</p>\n<p>总结下来步骤就是这样：</p>\n<ol>\n<li>\n<p>挖掘频繁项</p>\n</li>\n<li>\n<p>提取频繁项的各种统计特征</p>\n</li>\n<li>\n<p>频繁项和已经有的实体交集作为正样本，负采样得到负样本。使用多个分类器进行集成，训练多个二元分类器。</p>\n</li>\n</ol>\n<p>采用负样本的时候，美团有提到一个论文，大家可以去看一下。</p>\n<ol start=\"4\">\n<li>搜索日志中搜索次数比较高的词条和正样本的交集作为高质量短语，负样本减去词条作为低质量短语，使用Bert训练质量打分器。</li>\n</ol>\n<p>整个流程通读下来，其实很好理解。</p>\n<p>一般来讲，如果实践过程，第四个步骤其实很难做。</p>\n<p>我是这样想的，首先这个美团搜索很垂直，一般搜索属于短query，你很难去在美团搜索框去搜一个很长的句子。</p>\n<p>这种情况下，就会出顾客的搜索记录本身就是高质量的短语或者实体。想一下是不是这样，你去搜“来杯啤酒烧烤”，这本身就是个商户名称，就是个实体。所以交集才可以作为高质量短语。</p>\n<p>如果你是个大搜的搜索日志，这种情况基本不存在的，有长短语，有短的词汇，你找交集的阈值都无从下手。</p>\n<p>第二个难点就是Bert打分器这个东西的可靠性。一般来说实体的字数都比较少，比如五六个字，字数这么少，这个打分究竟可靠不可靠我没有实践过，只是有这个疑惑。</p>\n<p>整个做完，还有一个问题，实体库是分类别的，比如美食有一个词典，景点有一个词典等等吧。我们上面挖掘出来的是全部的实体，不分类别的，那么怎么分类呢？</p>\n<p>美团提到他们使用的AutoNER，大家可以去看一下相关论文。针对这一块，其实能做的思路还挺多的，由于工作原因，这块我就不说了。大家可以发散思路。</p>\n","link":"links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/关键词提取/实体库构建：大规模离线新词实体挖掘","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/关键词提取/实体库构建：大规模离线新词实体挖掘/","reward":true}