{"title":"","date":"2024-06-21T03:20:45.613Z","date_formatted":{"ll":"Jun 21, 2024","L":"06/21/2024","MM-DD":"06-21"},"updated":"2024-06-20T19:20:45.613Z","content":"<p>今天分享一个论文<a href=\"https://arxiv.org/pdf/2012.04987.pdf,\" title=\"Label Confusion Learning to Enhance Text Classification Models\" target=\"_blank\">LCM</a>；这个论文掌握以下几点，使用LCM模型：</p>\n<ol>\n<li>可以捕捉标签与标签之间的关系</li>\n<li>可以捕捉标签和样本之间的关系</li>\n<li>在噪声数据集，效果比LS要好</li>\n</ol>\n<h1 id=\"1.-文本分类普遍存在一个问题\">1. 文本分类普遍存在一个问题<a title=\"#1.-文本分类普遍存在一个问题\" href=\"#1.-文本分类普遍存在一个问题\"></a></h1>\n<p>深度学习模型进行文本分类有一个共性：</p>\n<ol>\n<li>\n<p>首先使用一个比较深的模型去做text representation；</p>\n</li>\n<li>\n<p>然后使用一个简单的分类层（比如全连接）去预测标签分布；</p>\n</li>\n<li>\n<p>之后计算预测标签分布和真实one-hot标签向量的交叉熵。</p>\n</li>\n</ol>\n<p>这个流程其实是有问题的；</p>\n<p>从标注规则来看，使用one-hot的前提是假设你的数据集中的标签是相互独立的。</p>\n<p>但是这种假设在现实中基本不会有，只是或多或少，有的界限比较清晰，有的不清晰的问题而已；</p>\n<p>还有一个问题从样本来看，如果是单标签分类，同一个样本真实情况下可能对应多个类别。</p>\n<p>比如【今天去公园野炊一下，吃点烧烤呗】；类别可能是【美食】，也可能是【旅游】，也可能是其他的类别。</p>\n<p>这个可能并不明显，我举个最明显的例子：【郭麒麟相声说的是真棒啊，综艺是真好看啊，综艺感真实爆棚了】；</p>\n<p>上面这个例子，你说它的类别是【相声】？【综艺】？【娱乐明星】？</p>\n<p>还有一个问题，就是标注错误的问题。这种情况一般使用标签平滑。</p>\n<p>标签平滑让真实标签不那么极端化，给与标签一定的容错概率。</p>\n<p>但是标签平滑本质上加了一个噪声，并不是真实反映标签的分布情况。</p>\n<p>从这出发，就可以看出下面LCM主要去解决以下问题：</p>\n<ol>\n<li>\n<p>标签之间并不相互独立，所以我们需要一种方式能够度量标签之间的关系</p>\n</li>\n<li>\n<p>样本可能对应多个标签，所以我们需要一种方式能够度量样本和每个标签之间的关系</p>\n</li>\n<li>\n<p>标签可能标注错误，所以我们尽量不适用one-hot硬标签，而是使用软化之后的标签。</p>\n</li>\n</ol>\n<h1 id=\"2.-lcm-架构图\">2. LCM-架构图<a title=\"#2.-lcm-架构图\" href=\"#2.-lcm-架构图\"></a></h1>\n<p>先来看架构图</p>\n<p><img src=\"https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-10-105718.jpg\" alt=\"LCM架构图\" loading=\"lazy\" class=\"φbp\"></p>\n<p>架构图最核心的部分注意看紫色的Similarity Layer层，这一层主要做的是对经过深度学习模型学到的句子表达和label的表达进行相似性度量。</p>\n<p>然后把这个相似性的度量加到one-hot标签中。</p>\n<p>看一下公式就明白了，左半部分比较简单，就不说了，看右半部分：</p>\n<p><img src=\"https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-10-105717.jpg\" alt=\"SLD\" loading=\"lazy\" class=\"φbp\"></p>\n<p>$f^{L}$是对labels进行encode，得到每个label的表达向量，方便和句子向量做 dot product。</p>\n<p>注意图中的参数$\\alpha$，代表了相似性这个信息对原始标签的影响。</p>\n<p>损失函数使用的是KL散度</p>\n<h1 id=\"3.-实验结果\">3. 实验结果<a title=\"#3.-实验结果\" href=\"#3.-实验结果\"></a></h1>\n<p>方法有效，就不放实验图了。</p>\n<p>我比较感兴趣的是 label embedding究竟有没有学到相似性，看图：</p>\n<p><img src=\"https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-10-105719.jpg\" alt=\"label representations\" loading=\"lazy\" class=\"φbp\"></p>\n<p>不同颜色代表将类别根据语义分为不同的组，可以看到同个颜色的labels很大情况下还是挨得很近的。</p>\n<p>说明架构图有半部分的下半部分，也就是那个label encoder确实是有作用的。</p>\n<p>还比较感兴趣的是LCM和标签平滑的对比，看图确实比LS更好一点：</p>\n<p><img src=\"https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-10-105715.jpg\" alt=\"LCM with LS\" loading=\"lazy\" class=\"φbp\"></p>\n<h1 id=\"总结\">总结<a title=\"#总结\" href=\"#总结\"></a></h1>\n<p>简单总结一下，</p>\n<ol>\n<li>LCM挖掘了标签之间的关系和标签与样本之间的关系</li>\n<li>样本数据如果噪声标签（标注错误），LCM有效</li>\n<li>样本数据的标签如果界限比较模糊（根据语义可以划分为多个组），LCM有效</li>\n</ol>\n<p>整个论文最核心的点，我认为是对lables做了编码，从而有机会去和句子编码进行交互，度量相似性。并将整个相似性信息加入到了原始标签中。</p>\n<p>所以网络在训练的时候，学习到的信息更加的丰富。</p>\n","link":"links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/LCM-缓解标签不独立以及标注错误的问题","comments":true,"plink":"http://www.ephesus.top/links/NLP_ability/深度学习自然语言处理/深度学习自然语言处理/文本分类/LCM-缓解标签不独立以及标注错误的问题/","toc":[{"id":"1.-文本分类普遍存在一个问题","title":"1. 文本分类普遍存在一个问题","index":"1"},{"id":"2.-lcm-架构图","title":"2. LCM-架构图","index":"2"},{"id":"3.-实验结果","title":"3. 实验结果","index":"3"},{"id":"总结","title":"总结","index":"4"}],"reward":true}